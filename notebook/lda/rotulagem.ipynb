{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo LDA de rotulagem de dados\n",
    "\n",
    "Esse notebook é uma implementação do modelo de classificação LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install texthero nltk -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyLDAvis in /home/guilherme.gomes/.local/lib/python3.6/site-packages (2.1.2)\n",
      "Requirement already satisfied: funcy in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pyLDAvis) (1.15)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /usr/lib/python3/dist-packages (from pyLDAvis) (0.30.0)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.10.1)\n",
      "Requirement already satisfied: pytest in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pyLDAvis) (6.1.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pyLDAvis) (1.1.4)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pyLDAvis) (1.17.0)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pyLDAvis) (1.3.1)\n",
      "Requirement already satisfied: numexpr in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pyLDAvis) (2.7.1)\n",
      "Requirement already satisfied: future in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.0)\n",
      "Requirement already satisfied: packaging in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pytest->pyLDAvis) (20.4)\n",
      "Requirement already satisfied: toml in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.10.2)\n",
      "Requirement already satisfied: iniconfig in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (19.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pytest->pyLDAvis) (2.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.9.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.13.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from packaging->pytest->pyLDAvis) (2.4.7)\n",
      "Requirement already satisfied: six in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from packaging->pytest->pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/guilherme.gomes/.local/lib/python3.6/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->pyLDAvis) (3.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/guilherme.gomes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import texthero as hero\n",
    "from texthero import preprocessing\n",
    "import plotly.express as px\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_full_lion_bbq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = ['video_title', 'comment', 'author',\n",
    "       'comment_cleaned', 'comment_stop_word', 'comment_tokenized',\n",
    "       'comment_stemming', 'comment_lematized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[*select]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leo         493\n",
       "top         433\n",
       "parabens    336\n",
       "manolo      272\n",
       "nao         263\n",
       "video       250\n",
       "bom         250\n",
       "pra         248\n",
       "vc          214\n",
       "carne       203\n",
       "ai          194\n",
       "abraco      168\n",
       "cara        165\n",
       "so          152\n",
       "demais      146\n",
       "Name: comment_stop_word, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = hero.visualization.top_words(df['comment_stop_word']).head(15)\n",
    "tw\n",
    "# fig = px.bar(tw)\n",
    "# fig.show()\n",
    "# tw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pronto                 1\n",
       "poderias               1\n",
       "karamba                1\n",
       "tubarao                1\n",
       "mantenhase             1\n",
       "inovacoes              1\n",
       "beijo                  1\n",
       "sensacionaaaallllll    1\n",
       "vegetais;hortalicas    1\n",
       "sinceros               1\n",
       "Name: comment_stop_word, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = hero.visualization.top_words(df['comment_stop_word']).tail(10)\n",
    "tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = ['leo','top','parabens', 'manolo','video','bom','pra','vc','carne','ai',\n",
    "#               'abraco','cara','so','demais']\n",
    "# df['comment_stop_word'] = df['comment_stop_word'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if len(token) > 3:\n",
    "            result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [mini, junta, pouco, gente, leva, nome, casame...\n",
       "1    [deus, abencoe, sempre, familia, parabens, bel...\n",
       "2       [quale, manollo, abre, pros, entrar, parabens]\n",
       "3     [manolo, voce, arrebentou, esqueceu, hidratacao]\n",
       "4    [caramba, amigos, orgulho, maximo, festival, p...\n",
       "5    [excelente, ambiente, descontraido, leve, tudo...\n",
       "6    [familia, amizades, legais, manolo, parabens, ...\n",
       "7    [demais, maravilha, senhor, nome, almiro, toda...\n",
       "8    [manolo, show, parabens, campinas, tomei, aqui...\n",
       "9    [manolo, emmmm, parabens, mini, evento, famili...\n",
       "Name: comment_stop_word, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = df['comment_stop_word'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "# less than 15 documents (absolute number) or\n",
    "# more than 0.5 (50%) documents (fraction of total corpus size, not absolute number).\n",
    "# after the above two steps, keep only the first 100000 most frequent tokens.\n",
    "\n",
    "id2word.filter_extremes(no_below=5, no_above=0.5, keep_n=100)\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('gente', 1), ('kkkkkk', 1)]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
